Inferencia estadística
======================

```{r , child = '_global_options.Rmd'}
```

El objetivo de este capítulo es ofrecer un primer acercamiento a la inferencia estadística,
cubriendo de forma somera los siguientes apartados:

* contrastes de normalidad
* contrastes paramétricos y no paramétricos, con una y dos muestras
* regresión y correlación
* análisis de la varianza con un factor

En este capítulo utilizaremos como ejemplo los datos de clientes de una compañía de distribución industrial (HATCO)
contenidos en el fichero *hatco.RData*.

```{r }
load('datos/hatco.RData')
```

Listado de etiquetas

```{r }
as.data.frame(attr(hatco, "variable.labels"))
```


Normalidad
----------
Queremos hacer un estudio inferencial de la variable *satisfac* (satisfacción global). Lo primero
que vamos a hacer es comprobar si, visualmente, los datos parecen razonablemente
simétricos y si se pueden ajustar por una distribución normal

```{r }
hist(hatco$satisfac)
qqnorm(hatco$satisfac)
shapiro.test(hatco$satisfac)
```


Contrastes
----------

### Una muestra

Obtenemos un intervalo de confianza de *satisfac*

```{r }
t.test(hatco$satisfac)  # with(hatco, t.test(satisfac))
```

Contrastamos si es razonable suponer que la media es 5

```{r }
t.test(hatco$satisfac, mu=5)
```

Utilizando una confianza del 99%

```{r }
t.test(hatco$satisfac, mu=5, conf.level=0.99)
```

Veamos si podemos afirmar que la media es menor que 5

```{r }
t.test(hatco$satisfac, mu=5, alternative = 'less')
```

¿Y mayor que 4.65?

```{r }
t.test(hatco$satisfac, mu=4.65, alternative = 'greater')
```

El test de los rangos con signo de Wilcoxon es un contraste no paramétrico
(exige que la distribución sea simétrica) que se puede utilizar como
alternativa al contraste *t* de Student

```{r }
with(hatco, wilcox.test(satisfac, mu=5))
```


### Dos muestras

Disponemos de dos muestras independientes, el porcentaje de compra
en las empresas con nivel de satisfacción bajo y alto,
y asumimos que las varianzas son iguales

```{r }
t.test(fidelida ~ nsatisfa, data = hatco, var.equal=TRUE)
```

Si no se asume igualdad de varianzas, se calcula la variante Welch del test *t*

```{r }
t.test(fidelida ~ nsatisfa, data = hatco)
```

Comparemos visualmente las varianzas

```{r }
boxplot(fidelida ~ nsatisfa, data = hatco)
```

La comparación de las varianzas puede hacerse con el test *F*

```{r }
var.test(fidelida ~ nsatisfa, data = hatco)
```

Una alternativa no paramétrica

```{r }
bartlett.test(fidelida ~ nsatisfa, data = hatco)
```

También puede utilizarse el test de Wilcoxon como alternativa al test *t*

```{r }
wilcox.test(fidelida ~ nsatisfa, data = hatco)
```

Si disponemos de datos apareados, por ejemplo nivel de precios e imagen
de fuerza de ventas

```{r }
with(hatco, t.test(precio, imgfvent, paired = TRUE))
```

Y la correspondiente alternativa no paramétrica

```{r }
with(hatco, wilcox.test(precio, imgfvent, paired = TRUE))
```


Regresión y correlación
-----------------------

### Regresión lineal simple

Utilizando la función *lm* (modelo lineal) se puede llevar a cabo, entre otras
muchas cosas, una regresión lineal simple

```{r }
lm(satisfac ~ fidelida, data = hatco)

modelo <- lm(satisfac ~ fidelida, data = hatco, na.action=na.exclude)
summary(modelo)

plot(hatco$fidelida, hatco$satisfac)      # Cuidado con el orden de las variables
# with(hatco, plot(fidelida, satisfac))   # Alternativa empleando with
# plot(satisfac ~ fidelida, data = hatco) # Alternativa empleando fórmulas
abline(modelo)
```

Valores ajustados

```{r }
fitted(modelo)
```

Residuos

```{r }
head(resid(modelo))
qqnorm(resid(modelo))
shapiro.test(resid(modelo))

plot(hatco$fidelida, hatco$satisfac)    

abline(modelo)
# segments(hatco$fidelida, fitted(modelo), hatco$fidelida, hatco$satisfac)
with(hatco, segments(fidelida, fitted(modelo), fidelida, satisfac))

plot(fitted(modelo), resid(modelo))
```

Banda de confianza

```{r }
predict(modelo, interval='confidence')
```

Banda de predicción

```{r }
head(predict(modelo, interval='prediction'))
```

Representación gráfica de las bandas

```{r }
bandas.frame <- data.frame(fidelida=24:66)
bc <- predict(modelo, interval = 'confidence', newdata = bandas.frame)
bp <- predict(modelo, interval = 'prediction', newdata = bandas.frame)
plot(hatco$fidelida, hatco$satisfac, ylim = range(hatco$satisfac, bp, na.rm = TRUE))
matlines(bandas.frame$fidelida, bc, lty=c(1,2,2), col='black')
matlines(bandas.frame$fidelida, bp, lty=c(0,3,3), col='red')
```


### Correlación

Coeficiente de correlación de Pearson

```{r }
cor(hatco$fidelida, hatco$satisfac, use='complete.obs')
cor(hatco[,6:14], use='complete.obs')
cor.test(hatco$fidelida, hatco$satisfac)
```

El coeficiente de correlación de Spearman es una variante no paramétrica

```{r }
cor.test(hatco$fidelida, hatco$satisfac, method='spearman')
```


Análisis de la varianza
-----------------------

### ANOVA con un factor

Vamos a estudiar si hay diferencias en las medias de la variable *satisfac*
(satisfacción global) entre los diferentes grupos definidos por *nfidelid*
(nivel de compra), utilizando el procedimiento clásico de análisis de la
varianza. Este procedimiento exige normalidad y homocedasticidad.

```{r }
table(hatco$nfidelid)
tapply(hatco$satisfac, hatco$nfidelid, mean, na.rm = TRUE)
```

La variable explicativa tiene que ser obligatoriamente de tipo *factor*.
Por coherencia con la función (general) *lm*, la variación entre grupos
está etiquetada *nfidelid*, y la variación dentro de los grupos como
*Residuals*

```{r }
anova(lm(satisfac~nfidelid, data = hatco))
```

Como alternativa, se puede utilizar la función *aov*

```{r }
aov(satisfac~nfidelid, data = hatco)
summary(aov(satisfac~nfidelid, data = hatco))
```

Comparaciones entre pares de variables

```{r }
pairwise.t.test(hatco$satisfac, hatco$nfidelid)
```

Relajamos la hipótesis de varianzas iguales

```{r }
oneway.test(satisfac~nfidelid, data = hatco)
```

Podemos utilizar el test de Bartlett para contrastar la igualdad de varianzas

```{r }
bartlett.test(satisfac~nfidelid, data = hatco)
```

Representación gráfica

```{r }
medias <- tapply(hatco$satisfac, hatco$nfidelid, mean, na.rm = TRUE)
desviaciones <- tapply(hatco$satisfac, hatco$nfidelid, sd, na.rm = TRUE)
n <- tapply(hatco$satisfac[!is.na(hatco$satisfac)], hatco$nfidelid[!is.na(hatco$satisfac)], length)
errores <- desviaciones/sqrt(n)
stripchart(hatco$satisfac~hatco$nfidelid, method='jitter', jit=0.01, pch=18, col='grey', vertical = TRUE)
arrows(1:3, medias+errores, 1:3, medias-errores, angle=90, code=3, lwd=2, col='orange')
points(1:3, medias, pch=4, lwd=2, cex=2, col='orange')
```


### Test de Kruskal-Wallis

Alternativa no paramétrica al análisis de la varianza con un factor

```{r }
kruskal.test(satisfac~nfidelid, data = hatco)
```
